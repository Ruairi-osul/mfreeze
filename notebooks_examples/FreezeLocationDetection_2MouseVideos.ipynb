{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze Location Tracking: 2 Mice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mfreeze.oop_interface import FreezeDetector, LoctionTracker\n",
    "from mfreeze.utils import crop_set_same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folders\n",
    "\n",
    "Here you specify where the videos to analyse are on your computer and where to save the results of the analysis. You should have all of the videos to analyse in a folder (directory).\n",
    "\n",
    "- **file_extention**: The file extention of the video files. Foe example `.mp4` or `.avi`.\n",
    "- **input_dir**: The folders where all of the conditioning videos are located.\n",
    "- **report_dir** : The folder where the results will be saved\n",
    "- **first_mouse_role**: The name of the role played by the first mouse to be analysed.\n",
    "- **second_mouse_role**: The name of the role played by the second mouse to be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these!\n",
    "\n",
    "file_extention = \".mp4\"\n",
    "input_dir = Path(r\"C:\\Users\\rory\\repos\\ah_vids\\raw_videos\\OG\")\n",
    "report_dir = Path(r\"C:\\Users\\rory\\repos\\ah_vids\\output\\OG\\conditioning\")\n",
    "first_mouse_role = \"obs\"\n",
    "second_mouse_role = \"dem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dir.mkdir(exist_ok=True)\n",
    "done_vids = []\n",
    "videos = list(input_dir.glob(f\"*{file_extention}\"))\n",
    "video_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. New Video Here\n",
    "\n",
    "Running the below cell will move on to the next video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    current_video = str(videos[video_index])\n",
    "    print(f\"Current Video:\\n\\t{current_video}\")\n",
    "except IndexError:\n",
    "    print(\"No more videos left to analyse!\", \"\\n\")\n",
    "    print(\"Check the contents of `done_vids` to make \"\n",
    "          \"sure all of the videos to be analysed have been.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjustable Parameters\n",
    "\n",
    "Change these values to alter the performance of the freeze detection / location tracking.\n",
    "\n",
    "**Do not assume that things are working well**.\n",
    "Choose some initial values for these parameters, run the analysis and examine the videos that are produced in `report_dir`. if they are not good, *adjust these parameters*.\n",
    "\n",
    "- **start_frame**: All frames before this will be cropped out. It defaults to the first frame. If there is a lot of movement at the start of the video (for example, from placing the camera into place), it is a good idea to crop it out.\n",
    "- **mouse1_freeze_threshold**: Freeze Threshold for the first mouse. If too many frames are being classified as freezes, *lower* this value.\n",
    "- **mouse2_freeze_threshold**: Freeze Threshold for the second mouse. If too many frames are being classified as freezes, *lower* this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these!\n",
    "\n",
    "start_frame = 0\n",
    "mouse1_freeze_threshold = -0.7\n",
    "mouse2_freeze_threshold = -0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = first_mouse_role\n",
    "detector = FreezeDetector(\n",
    "    current_video, \n",
    "    save_video_dir=report_dir,\n",
    "    freeze_threshold=mouse1_freeze_threshold, \n",
    "    start_frame=start_frame,\n",
    "    med_filter_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping\n",
    "\n",
    "Cropping only the area around the first mouse. To crop:\n",
    "\n",
    "1. Run the cell below. You should see an image of a frame and some buttons below it.\n",
    "2. Click this button\n",
    "<img src=\"crop_tool.png\">\n",
    "3. Double click frame\n",
    "4. Draw a box around the area to include in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, c  = detector.interactive_crop(frame=start_frame)\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b07e02b3ebdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_motion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_freezes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m tracker = LoctionTracker(vid, start_frame=start_frame, \n",
      "\u001b[1;31mNameError\u001b[0m: name 'detector' is not defined"
     ]
    }
   ],
   "source": [
    "detector.detect_motion()\n",
    "detector.detect_freezes()\n",
    "detector.save_video()\n",
    "\n",
    "tracker = LoctionTracker(\n",
    "    current_video, \n",
    "    start_frame=start_frame, \n",
    "    save_video_dir=report_dir,\n",
    "    reference_num_frames=1000,\n",
    ")\n",
    "tracker = crop_set_same(detector, tracker)\n",
    "tracker.track_location()\n",
    "tracker.save_video()\n",
    "\n",
    "dff = detector.generate_report()\n",
    "dft = tracker.generate_report()\n",
    "dfm1 = (\n",
    "    pd.merge(dff, dft, on=[\"frame\", \"time\", \"video_name\", \"fps\"])\n",
    "    .rename(columns=({\"was_freezing\": f\"was_freezing_{ROLE}\",\n",
    "                     \"x\": f\"x_{ROLE}\",\n",
    "                     \"y\": f\"y_{ROLE}\",\n",
    "                     \"distance\": f\"distance_{ROLE}\"}))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Mouse\n",
    "\n",
    "All we need to do is **crop**. This time, crop the chamber of the second mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = second_mouse_role\n",
    "detector = FreezeDetector(\n",
    "    current_video, \n",
    "    save_video_dir=report_dir,\n",
    "    freeze_threshold=mouse2_freeze_threshold, \n",
    "    start_frame=start_frame,\n",
    "    med_filter_size=5\n",
    ")\n",
    "i, c  = detector.interactive_crop(frame=start_frame)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.detect_motion()\n",
    "detector.detect_freezes()\n",
    "detector.save_video()\n",
    "\n",
    "tracker = LoctionTracker(\n",
    "    current_video, \n",
    "    start_frame=start_frame, \n",
    "    save_video_dir=report_dir,\n",
    "    reference_num_frames=1000,\n",
    ")\n",
    "tracker = crop_set_same(detector, tracker)\n",
    "tracker.track_location()\n",
    "tracker.save_video()\n",
    "\n",
    "dff = detector.generate_report()\n",
    "dft = tracker.generate_report()\n",
    "dfm2 = (\n",
    "    pd.merge(dff, dft, on=[\"frame\", \"time\", \"video_name\", \"fps\"])\n",
    "    .rename(columns=({\"was_freezing\": f\"was_freezing_{ROLE}\",\n",
    "                     \"x\": f\"x_{ROLE}\",\n",
    "                     \"y\": f\"y_{ROLE}\",\n",
    "                     \"distance\": f\"distance_{ROLE}\"}))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Combined Report and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.merge(dfm1, dfm2)\n",
    "    .to_csv(report_dir / f\"{Path(current_video).stem}.csv\", index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move onto the Next Video\n",
    "\n",
    "To move onto the next video, run the cell below then go back to the cell below **1. New Video Here**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_vids.append(vid)\n",
    "print(len(done_vids))\n",
    "\n",
    "video_index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
